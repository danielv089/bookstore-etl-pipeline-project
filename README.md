# Python ETL Project: Scraping, Transforming, and Loading Book Data

## ğŸ“Œ Overview
This project is a complete **ETL (Extract, Transform, Load) pipeline** built in Python.  
It scrapes book data from the web, cleans and normalizes it, and loads it into a SQL database.  
The goal is to demonstrate a practical, end-to-end data engineering workflow using Python and containerization with Docker.

## âš™ï¸ ETL Pipeline Steps

### 1ï¸âƒ£ Extract
- Scrapes all catalog pages from [Books to Scrape](https://books.toscrape.com/).
- Retrieves metadata: title, genre, rating, price, stock availability, UPC, and number of reviews.
- Saves raw data to 1_extract_raw_data


### 2ï¸âƒ£ Transform
- Removes duplicates and null values
- Standardizes data types and formats
- Reclassifies Default and Add a comment genrew into Uncategorized
- Maps rating strings to numerical values
- Cleans currency symbols and parses stock quantities
- Saves cleaned data to 2_transform_data/books_cleaned_data.csv/books_raw_data.csv

### 3ï¸âƒ£ Normalize
- Extracts a genre lookup table
- Replaces genre strings with foreign key IDs
- Splits in_stock data into its own table
- Saves normalized CSV files to 3_normalized_data/

### 4ï¸âƒ£ Load
- Loads normalized tables into a SQL database

  ![ETL Pipeline Diagram](docs/etl_project.jpg)


## ğŸ³ Docker Support

- **v2.0 â€“ Python, PostgreSQL  & Docker Compose Integration**
   
    The ETL pipeline is containerized with     Docker Compose for multi-container deployment, including:

    PostgreSQL database as backend

    Python ETL container

    Build and start the containers:
    ```bash
    docker compose up --build
    ```
    PostgreSQL connection is configured via environment variables in docker-compose.yml
    PostgreSQL data is stored in the pgdata named perstistent volume.


    Data inside the PostgreSQL container:

    ![DB](docs/books_db.png)

    ![tables](docs/tables.png)

    ![books_table](docs/books_table.png)

    ![count](docs/item_count.png)

  [Exported pg_dump file after the the pipeline run with Docker Compose](v2.0_postgres_docker_compose/data/postgres_dump_data_sql/books.sql)


- **v1.5 â€“ Python, SQLite and Docker**
  
    This ETL pipeline is containerized for easier deployment.

    Build the Docker image:

    ```bash
    docker build -t  v1.5_sqlite
    ```
    Run the Docker container with volumes to map folders inside the container to folders on the host machine:

    ```bash
    docker run -it --rm -v "$PWD/data":/app/data -v "$PWD/logs":/app/logs v1.5_sqlite
     ```


[![changelog](https://img.shields.io/badge/changelog-blue?style=for-the-badge)
](CHANGELOG.md)

## ğŸ§° Tech Stack
- **Python**
- **Pandas** 
- **Requests**
- **BeautifulSoup4**
- **SQLite3** 
- **Logging**
- **Docker**
- **Pytest**
- **PostgreSQL**
- **Psycopg**

## ğŸ“ V2.0 Folder Structure
``` 
â”€â”€ v2.0_postgres_docker_compose
    â”œâ”€â”€ data
    â”‚   â”œâ”€â”€ 1_extract_raw_data
    â”‚   â”‚   â””â”€â”€ books_raw_data.csv
    â”‚   â”œâ”€â”€ 2_transform_data
    â”‚   â”‚   â””â”€â”€ books_cleaned_data.csv
    â”‚   â”œâ”€â”€ 3_normalized_data
    â”‚   â”‚   â”œâ”€â”€ books.csv
    â”‚   â”‚   â”œâ”€â”€ genres.csv
    â”‚   â”‚   â””â”€â”€ in_stock.csv
    â”‚   â””â”€â”€ postgres_dump_data_sql
    â”‚       â””â”€â”€ books.sql
    â”œâ”€â”€ docker-compose.yml
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ etl
    â”‚   â”œâ”€â”€ extract.py
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ load.py
    â”‚   â”œâ”€â”€ logger.py
    â”‚   â”œâ”€â”€ normalize.py
    â”‚   â””â”€â”€ transform.py
    â”œâ”€â”€ logs
    â”‚   â””â”€â”€ pipeline_logs.txt
    â”œâ”€â”€ main.py
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ tests
        â””â”€â”€ test_etl.py
``` 

## ğŸ”— References

- Books to Scrape
https://books.toscrape.com/

- Pandas Documentation
https://pandas.pydata.org/docs/

- BeautifulSoup Documentation
https://www.crummy.com/software/BeautifulSoup/bs4/doc/

- Requests Library
https://docs.python-requests.org/

- SQLite3
https://docs.python.org/3/library/sqlite3.html

- Python Logging Module
https://docs.python.org/3/library/logging.html

- Docker Documentation
https://docs.docker.com/

- PostgreSQL Documentation
https://www.postgresql.org/docs/

- Psycopg Documentation
https://www.psycopg.org/

âœ… This project uses only publicly available data for educational purposes.
